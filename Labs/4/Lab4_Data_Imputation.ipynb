{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OhtOdxzd1ppr"
   },
   "source": [
    "# Lab 4: Data Imputation using an Autoencoder\n",
    "\n",
    "\n",
    "In this lab, you will build and train an autoencoder to impute (or \"fill in\") missing data. \n",
    "\n",
    "We will be using the\n",
    "Adult Data Set provided by the UCI Machine Learning Repository [1], available \n",
    "at https://archive.ics.uci.edu/ml/datasets/adult.\n",
    "The data set contains census record files of adults, including their\n",
    "age, martial status, the type of work they do, and other features. \n",
    "\n",
    "Normally, people use this data set to build a supervised classification\n",
    "model to classify whether a person is a high income earner.\n",
    "We will not use the dataset for this original intended purpose.\n",
    "\n",
    "Instead, we will perform the task of imputing (or \"filling in\") missing values in the dataset. For example,\n",
    "we may be missing one person's martial status, and another person's age, and\n",
    "a third person's level of education. Our model will predict the missing features \n",
    "based on the information that we do have about each person.\n",
    "\n",
    "We will use a variation of a denoising autoencoder to solve this data imputation\n",
    "problem. Our autoencoder will be trained using inputs that have one categorical feature artificially\n",
    "removed, and the goal of the autoencoder is to correctly reconstruct all features,\n",
    "including the one removed from the input.\n",
    "\n",
    "In the process, you are expected to learn to:\n",
    "\n",
    "1. Clean and process continuous and categorical data for machine learning.\n",
    "2. Implement an autoencoder that takes continuous and categorical (one-hot) inputs.\n",
    "3. Tune the hyperparameters of an autoencoder.\n",
    "4. Use baseline models to help interpret model performance.\n",
    "\n",
    "[1] Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "\n",
    "### What to submit\n",
    "\n",
    "Submit a PDF file containing all your code, outputs, and write-up. You can produce a PDF of your Google Colab file by going to File > Print and then save as PDF. The Colab instructions have more information.\n",
    "\n",
    "Do not submit any other files produced by your code.\n",
    "\n",
    "Include a link to your colab file in your submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbnrp2ig1pps"
   },
   "source": [
    "## Colab Link\n",
    "\n",
    "Include a link to your Colab file here. If you would like the TA to look at your\n",
    "Colab file in case your solutions are cut off, **please make sure that your Colab\n",
    "file is publicly accessible at the time of submission**.\n",
    "\n",
    "Colab Link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "z3p8N43E1ppt",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ROwtHcz1ppx"
   },
   "source": [
    "## Part 0\n",
    "\n",
    "We will be using a package called `pandas` for this assignment. \n",
    "\n",
    "If you are using Colab, `pandas` should already be available.\n",
    "If you are using your own computer,\n",
    "installation instructions for `pandas` are available here: \n",
    "https://pandas.pydata.org/pandas-docs/stable/install.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IXQ7BP151ppz",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqXihb4Q1pp2"
   },
   "source": [
    "# Part 1. Data Cleaning [15 pt]\n",
    "\n",
    "The adult.data file is available at `https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data`\n",
    "\n",
    "The function `pd.read_csv` loads the adult.data file into a pandas dataframe.\n",
    "You can read about the pandas documentation for `pd.read_csv` at\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EOMItFKn1pp3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9_/z_hkcvrx4150jhlxkgq00mv40000gn/T/ipykernel_9644/1831985018.py:3: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "header = ['age', 'work', 'fnlwgt', 'edu', 'yredu', 'marriage', 'occupation',\n",
    " 'relationship', 'race', 'sex', 'capgain', 'caploss', 'workhr', 'country']\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "    names=header,\n",
    "    index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62Ot405q1pp5",
    "outputId": "c90e1be4-182d-4816-c20f-5d65fe414844",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # there are 32561 rows (records) in the data frame, and 14 columns (features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tr7YG-QY1pp8"
   },
   "source": [
    "### Part (a) Continuous Features [3 pt]\n",
    "\n",
    "For each of the columns `[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]`, report the minimum, maximum, and average value across the dataset. \n",
    "\n",
    "Then, normalize each of the features `[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]`\n",
    "so that their values are always between 0 and 1.\n",
    "Make sure that you are actually modifying the dataframe `df`. \n",
    "\n",
    "Like numpy arrays and torch tensors, \n",
    "pandas data frames can be sliced. For example, we can\n",
    "display the first 3 rows of the data frame (3 records) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9evSLsSa1pp9",
    "outputId": "cd1c2aee-df56-4df1-df16-3247d929a7b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>work</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>edu</th>\n",
       "      <th>yredu</th>\n",
       "      <th>marriage</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capgain</th>\n",
       "      <th>caploss</th>\n",
       "      <th>workhr</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age               work  fnlwgt         edu  yredu             marriage  \\\n",
       "0   39          State-gov   77516   Bachelors     13        Never-married   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors     13   Married-civ-spouse   \n",
       "2   38            Private  215646     HS-grad      9             Divorced   \n",
       "\n",
       "           occupation    relationship    race    sex  capgain  caploss  \\\n",
       "0        Adm-clerical   Not-in-family   White   Male     2174        0   \n",
       "1     Exec-managerial         Husband   White   Male        0        0   \n",
       "2   Handlers-cleaners   Not-in-family   White   Male        0        0   \n",
       "\n",
       "   workhr         country  \n",
       "0      40   United-States  \n",
       "1      13   United-States  \n",
       "2      40   United-States  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:3] # show the first 3 records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBOojI6W1pqA"
   },
   "source": [
    "Alternatively, we can slice based on column names, \n",
    "for example `df[\"race\"]`, `df[\"hr\"]`, or even index multiple columns \n",
    "like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4v6pp73A1pqB",
    "outputId": "80c34c3c-4df7-414d-ffe4-9ff73b81b68a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>yredu</th>\n",
       "      <th>capgain</th>\n",
       "      <th>caploss</th>\n",
       "      <th>workhr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  yredu  capgain  caploss  workhr\n",
       "0   39     13     2174        0      40\n",
       "1   50     13        0        0      13\n",
       "2   38      9        0        0      40"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf = df[[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]]\n",
    "subdf[:3] # show the first 3 records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Nru2P0E1pqD"
   },
   "source": [
    "Numpy works nicely with pandas, like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXrS6tjp1pqE",
    "outputId": "29ee3639-30ae-4533-cb73-7cddf4be82a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2842700"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(subdf[\"caploss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mv5mbxDM1pqH"
   },
   "source": [
    "Just like numpy arrays, you can modify\n",
    "entire columns of data rather than one scalar element at a time.\n",
    "For example, the code  \n",
    "\n",
    "`df[\"age\"] = df[\"age\"] + 1` \n",
    "\n",
    "would increment everyone's age by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "k5rlWD7-1pqH",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Min    Max         Mean\n",
      "age       17     90    38.581647\n",
      "yredu      1     16    10.080679\n",
      "capgain    0  99999  1077.648844\n",
      "caploss    0   4356    87.303830\n",
      "workhr     1     99    40.437456\n"
     ]
    }
   ],
   "source": [
    "#Calculate min, max ,and average values\n",
    "columns = [\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]\n",
    "min_values = df[columns].min()\n",
    "max_values = df[columns].max()\n",
    "mean_values = df[columns].mean()\n",
    "\n",
    "#Display the summary\n",
    "summary = pd.DataFrame({\n",
    "    'Min': min_values, \n",
    "    'Max': max_values,\n",
    "    'Mean': mean_values\n",
    "})\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age     yredu  capgain  caploss    workhr\n",
      "0  0.301370  0.800000  0.02174      0.0  0.397959\n",
      "1  0.452055  0.800000  0.00000      0.0  0.122449\n",
      "2  0.287671  0.533333  0.00000      0.0  0.397959\n"
     ]
    }
   ],
   "source": [
    "#Normalize the spcified columns\n",
    "for column in columns:\n",
    "    min_val = min_values[column]\n",
    "    max_val = max_values[column]\n",
    "    df[column] = (df[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "#Display the first 3 records to verify normalization\n",
    "print(df[[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qbfMly4R1pqK"
   },
   "source": [
    "### Part (b) Categorical Features [1 pt]\n",
    "\n",
    "What percentage of people in our data set are male? Note that the data labels all have an unfortunate space in the beginning, e.g. \" Male\" instead of \"Male\".\n",
    "\n",
    "What percentage of people in our data set are female?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DjAjcsB_1pqK",
    "outputId": "cd7201c3-007c-4fea-d955-4ce34ff808b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of males: 66.92%\n",
      "Percentage of females: 33.08%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe percentage of people in our data being female is 33.08%\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_males = sum(df[\"sex\"] == \" Male\")\n",
    "num_females = sum(df[\"sex\"] == \" Female\")\n",
    "\n",
    "total_entries = len(df)\n",
    "percent_males = (num_males / total_entries) * 100\n",
    "percent_females = (num_females / total_entries) * 100\n",
    "\n",
    "print(f\"Percentage of males: {percent_males:.2f}%\")\n",
    "print(f\"Percentage of females: {percent_females:.2f}%\")\n",
    "\n",
    "'''\n",
    "The percentage of people in our data being female is 33.08%\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eGVw7pqL1pqN"
   },
   "source": [
    "### Part (c) [2 pt]\n",
    "\n",
    "Before proceeding, we will modify our data frame in a couple more ways:\n",
    "\n",
    "1. We will restrict ourselves to using a subset of the features (to simplify our autoencoder)\n",
    "2. We will remove any records (rows) already containing missing values, and store them in a second dataframe. We will only use records without missing values to train our autoencoder.\n",
    "\n",
    "Both of these steps are done for you, below.\n",
    "\n",
    "How many records contained missing features? What percentage of records were removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "z6ewPUdv1pqO",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "contcols = [\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]\n",
    "catcols = [\"work\", \"marriage\", \"occupation\", \"edu\", \"relationship\", \"sex\"]\n",
    "features = contcols + catcols\n",
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fjdVll5a1pqQ",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "missing = pd.concat([df[c] == \" ?\" for c in catcols], axis=1).any(axis=1)\n",
    "df_with_missing = df[missing]\n",
    "df_not_missing = df[~missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with missing features: 1843\n",
      "Percentage of records removed: 5.66%\n"
     ]
    }
   ],
   "source": [
    "#Count the number of records in both DataFrames\n",
    "num_missing = len(df_with_missing)\n",
    "num_not_missing = len(df_not_missing)\n",
    "total_records = len(df)\n",
    "\n",
    "#Calculate the percentage\n",
    "percent_removed = (num_missing / total_records) * 100\n",
    "\n",
    "print(f\"Number of records with missing features: {num_missing}\")\n",
    "print(f\"Percentage of records removed: {percent_removed:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XuEpndTQ1pqU"
   },
   "source": [
    "### Part (d) One-Hot Encoding [1 pt]\n",
    "\n",
    "What are all the possible values of the feature \"work\" in `df_not_missing`? You may find the Python function `set` useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iKFh4owE1pqV",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible values of the feature 'work': {work_values}\n",
      "        age     yredu  capgain  caploss    workhr  work_ Federal-gov  \\\n",
      "0  0.301370  0.800000  0.02174      0.0  0.397959              False   \n",
      "1  0.452055  0.800000  0.00000      0.0  0.122449              False   \n",
      "2  0.287671  0.533333  0.00000      0.0  0.397959              False   \n",
      "3  0.493151  0.400000  0.00000      0.0  0.397959              False   \n",
      "4  0.150685  0.800000  0.00000      0.0  0.397959              False   \n",
      "\n",
      "   work_ Local-gov  work_ Private  work_ Self-emp-inc  work_ Self-emp-not-inc  \\\n",
      "0            False          False               False                   False   \n",
      "1            False          False               False                    True   \n",
      "2            False           True               False                   False   \n",
      "3            False           True               False                   False   \n",
      "4            False           True               False                   False   \n",
      "\n",
      "   ...  edu_ Prof-school  edu_ Some-college  relationship_ Husband  \\\n",
      "0  ...             False              False                  False   \n",
      "1  ...             False              False                   True   \n",
      "2  ...             False              False                  False   \n",
      "3  ...             False              False                   True   \n",
      "4  ...             False              False                  False   \n",
      "\n",
      "   relationship_ Not-in-family  relationship_ Other-relative  \\\n",
      "0                         True                         False   \n",
      "1                        False                         False   \n",
      "2                         True                         False   \n",
      "3                        False                         False   \n",
      "4                        False                         False   \n",
      "\n",
      "   relationship_ Own-child  relationship_ Unmarried  relationship_ Wife  \\\n",
      "0                    False                    False               False   \n",
      "1                    False                    False               False   \n",
      "2                    False                    False               False   \n",
      "3                    False                    False               False   \n",
      "4                    False                    False                True   \n",
      "\n",
      "   sex_ Female  sex_ Male  \n",
      "0        False       True  \n",
      "1        False       True  \n",
      "2        False       True  \n",
      "3        False       True  \n",
      "4         True      False  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "work_values = set(df_not_missing[\"work\"])\n",
    "df_not_missing_ecoded = pd.get_dummies(df_not_missing, \n",
    "                                       columns=catcols)\n",
    "\n",
    "print(\"All possible values of the feature 'work': {work_values}\")\n",
    "print(df_not_missing_ecoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COv3HaKr1pqY"
   },
   "source": [
    "We will be using a one-hot encoding to represent each of the categorical variables.\n",
    "Our autoencoder will be trained using these one-hot encodings.\n",
    "\n",
    "We will use the pandas function `get_dummies` to produce one-hot encodings\n",
    "for all of the categorical variables in `df_not_missing`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "eKlSYmJg1pqZ",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(df_not_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3y7nTZ7H1pqb",
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>yredu</th>\n",
       "      <th>capgain</th>\n",
       "      <th>caploss</th>\n",
       "      <th>workhr</th>\n",
       "      <th>work_ Federal-gov</th>\n",
       "      <th>work_ Local-gov</th>\n",
       "      <th>work_ Private</th>\n",
       "      <th>work_ Self-emp-inc</th>\n",
       "      <th>work_ Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>edu_ Prof-school</th>\n",
       "      <th>edu_ Some-college</th>\n",
       "      <th>relationship_ Husband</th>\n",
       "      <th>relationship_ Not-in-family</th>\n",
       "      <th>relationship_ Other-relative</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age     yredu  capgain  caploss    workhr  work_ Federal-gov  \\\n",
       "0  0.301370  0.800000  0.02174      0.0  0.397959              False   \n",
       "1  0.452055  0.800000  0.00000      0.0  0.122449              False   \n",
       "2  0.287671  0.533333  0.00000      0.0  0.397959              False   \n",
       "\n",
       "   work_ Local-gov  work_ Private  work_ Self-emp-inc  work_ Self-emp-not-inc  \\\n",
       "0            False          False               False                   False   \n",
       "1            False          False               False                    True   \n",
       "2            False           True               False                   False   \n",
       "\n",
       "   ...  edu_ Prof-school  edu_ Some-college  relationship_ Husband  \\\n",
       "0  ...             False              False                  False   \n",
       "1  ...             False              False                   True   \n",
       "2  ...             False              False                  False   \n",
       "\n",
       "   relationship_ Not-in-family  relationship_ Other-relative  \\\n",
       "0                         True                         False   \n",
       "1                        False                         False   \n",
       "2                         True                         False   \n",
       "\n",
       "   relationship_ Own-child  relationship_ Unmarried  relationship_ Wife  \\\n",
       "0                    False                    False               False   \n",
       "1                    False                    False               False   \n",
       "2                    False                    False               False   \n",
       "\n",
       "   sex_ Female  sex_ Male  \n",
       "0        False       True  \n",
       "1        False       True  \n",
       "2        False       True  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HwjDg1uM1pqe"
   },
   "source": [
    "### Part (e) One-Hot Encoding [2 pt]\n",
    "\n",
    "The dataframe `data` contains the cleaned and normalized data that we will use to train our denoising autoencoder.\n",
    "\n",
    "How many **columns** (features) are in the dataframe `data`?\n",
    "\n",
    "Briefly explain where that number come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yjZ5N0Tl1pqf",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns (features) in the dataframe 'data': 57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The total number of columns consists of continous features\\nand categorical features (one-hot encoded). There are 5 \\ncontinous featuers among age, yredu, capgain, etc.\\nand (presumably) 52 categorical featuresd istributed among \\nwork, marriage, occupation, etc.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_not_missing_ecoded\n",
    "num_columns = data.shape[1]\n",
    "\n",
    "print(f\"Number of columns (features) in the dataframe 'data': {num_columns}\")\n",
    "\n",
    "'''The total number of columns consists of continous features\n",
    "and categorical features (one-hot encoded). There are 5 \n",
    "continous featuers among age, yredu, capgain, etc.\n",
    "and (presumably) 52 categorical featuresd istributed among \n",
    "work, marriage, occupation, etc.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OEJ0Ci3l1pqh"
   },
   "source": [
    "### Part (f) One-Hot Conversion [3 pt]\n",
    "\n",
    "We will convert the pandas data frame `data` into numpy, so that\n",
    "it can be further converted into a PyTorch tensor.\n",
    "However, in doing so, we lose the column label information that\n",
    "a panda data frame automatically stores.\n",
    "\n",
    "Complete the function `get_categorical_value` that will return\n",
    "the named value of a feature given a one-hot embedding.\n",
    "You may find the global variables `cat_index` and `cat_values`\n",
    "useful. (Display them and figure out what they are first.)\n",
    "\n",
    "We will need this function in the next part of the lab\n",
    "to interpret our autoencoder outputs. So, the input\n",
    "to our function `get_categorical_values` might not \n",
    "actually be \"one-hot\" -- the input may instead \n",
    "contain real-valued predictions from our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZmovX6gu1pqi",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "datanp = data.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YRIa5MBd1pql",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cat_index = {}  # Mapping of feature -> start index of feature in a record\n",
    "cat_values = {} # Mapping of feature -> list of categorical values the feature can take\n",
    "\n",
    "# build up the cat_index and cat_values dictionary\n",
    "for i, header in enumerate(data.keys()):\n",
    "    if \"_\" in header: # categorical header\n",
    "        feature, value = header.split()\n",
    "        feature = feature[:-1] # remove the last char; it is always an underscore\n",
    "        if feature not in cat_index:\n",
    "            cat_index[feature] = i\n",
    "            cat_values[feature] = [value]\n",
    "        else:\n",
    "            cat_values[feature].append(value)\n",
    "\n",
    "def get_onehot(record, feature):\n",
    "    \"\"\"\n",
    "    Return the portion of `record` that is the one-hot encoding\n",
    "    of `feature`. For example, since the feature \"work\" is stored\n",
    "    in the indices [5:12] in each record, calling `get_range(record, \"work\")`\n",
    "    is equivalent to accessing `record[5:12]`.\n",
    "    \n",
    "    Args:\n",
    "        - record: a numpy array representing one record, formatted\n",
    "                  the same way as a row in `data.np`\n",
    "        - feature: a string, should be an element of `catcols`\n",
    "    \"\"\"\n",
    "    start_index = cat_index[feature]\n",
    "    stop_index = cat_index[feature] + len(cat_values[feature])\n",
    "    return record[start_index:stop_index]\n",
    "\n",
    "def get_categorical_value(onehot, feature):\n",
    "    \"\"\"\n",
    "    Return the categorical value name of a feature given\n",
    "    a one-hot vector representing the feature.\n",
    "    \n",
    "    Args:\n",
    "        - onehot: a numpy array one-hot representation of the feature\n",
    "        - feature: a string, should be an element of `catcols`\n",
    "        \n",
    "    Examples:\n",
    "    \n",
    "    >>> get_categorical_value(np.array([0., 0., 0., 0., 0., 1., 0.]), \"work\")\n",
    "    'State-gov'\n",
    "    >>> get_categorical_value(np.array([0.1, 0., 1.1, 0.2, 0., 1., 0.]), \"work\")\n",
    "    'Private'\n",
    "    \"\"\"\n",
    "    # <----- TODO: WRITE YOUR CODE HERE ----->\n",
    "    # You may find the variables `cat_index` and `cat_values` \n",
    "    # (created above) useful.\n",
    "    max_index = np.argmax(onehot)\n",
    "    return cat_values[feature][max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example record's 'work' feature one-hot encoding: [0. 0. 0. 0. 0. 1. 0.]\n",
      "Example records's 'work' feature categorical value: State-gov\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "example_record = datanp[0]\n",
    "example_onehot_work = get_onehot(example_record, \"work\")\n",
    "example_categorical_value = get_categorical_value(example_onehot_work,\n",
    "                                                  \"work\")\n",
    "print(f\"Example record's 'work' feature one-hot encoding: {example_onehot_work}\")\n",
    "print(f\"Example records's 'work' feature categorical value: {example_categorical_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "T_XXxZdh1pqv",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# more useful code, used during training, that depends on the function\n",
    "# you write above\n",
    "\n",
    "def get_feature(record, feature):\n",
    "    \"\"\"\n",
    "    Return the categorical feature value of a record\n",
    "    \"\"\"\n",
    "    onehot = get_onehot(record, feature)\n",
    "    return get_categorical_value(onehot, feature)\n",
    "\n",
    "def get_features(record):\n",
    "    \"\"\"\n",
    "    Return a dictionary of all categorical feature values of a record\n",
    "    \"\"\"\n",
    "    return { f: get_feature(record, f) for f in catcols }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example record's categorical features: {'work': 'State-gov', 'marriage': 'Never-married', 'occupation': 'Adm-clerical', 'edu': 'Bachelors', 'relationship': 'Not-in-family', 'sex': 'Male'}\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "example_categorical_features = get_features(example_record)\n",
    "print(f\"Example record's categorical features: {example_categorical_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_5ZZR_J1pqy"
   },
   "source": [
    "### Part (g) Train/Test Split [3 pt]\n",
    "\n",
    "Randomly split the data into approximately 70% training, 15% validation and 15% test.\n",
    "\n",
    "Report the number of items in your training, validation, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TE_fTJJf1pqz",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in the training set: 21502\n",
      "Number of items in the validation set: 4608\n",
      "Number of items in the test set: 4608\n"
     ]
    }
   ],
   "source": [
    "# set the numpy seed for reproducibility\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.seed.html\n",
    "np.random.seed(50)\n",
    "\n",
    "# todo\n",
    "num_records = datanp.shape[0]\n",
    "indices = np.arange(num_records)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_end = int(0.70 * num_records)\n",
    "val_end = int(0.85 * num_records)\n",
    "\n",
    "#Split\n",
    "train_ind = indices[:train_end]\n",
    "val_ind = indices[train_end:val_end]\n",
    "test_ind = indices[val_end:]\n",
    "\n",
    "#Create sets\n",
    "train_set = datanp[train_ind]\n",
    "val_set = datanp[val_ind]\n",
    "test_set = datanp[test_ind]\n",
    "\n",
    "num_train = train_set.shape[0]\n",
    "num_val = val_set.shape[0]\n",
    "num_test = test_set.shape[0]\n",
    "\n",
    "print(f\"Number of items in the training set: {num_train}\")\n",
    "print(f\"Number of items in the validation set: {num_val}\")\n",
    "print(f\"Number of items in the test set: {num_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h9wJAKOI1pq3"
   },
   "source": [
    "## Part 2. Model Setup [5 pt]\n",
    "\n",
    "### Part (a) [4 pt]\n",
    "\n",
    "Design a fully-connected autoencoder by modifying the `encoder` and `decoder`\n",
    "below.\n",
    "\n",
    "The input to this autoencoder will be the features of the `data`, with\n",
    "one categorical feature recorded as \"missing\". The output of the autoencoder\n",
    "should be the reconstruction of the same features, but with the missing\n",
    "value filled in.\n",
    "\n",
    "**Note**: Do not reduce the dimensionality of the input too much!\n",
    "The output of your embedding is expected to contain information \n",
    "about ~11 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "f3F--tdn1pq3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(57, 40), # TODO -- FILL OUT THE CODE HERE!\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 11)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(11, 20), # TODO -- FILL OUT THE CODE HERE!\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40,57),\n",
    "            nn.Sigmoid() # get to the range (0, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuEzTSAv1pq6"
   },
   "source": [
    "### Part (b) [1 pt]\n",
    "\n",
    "Explain why there is a sigmoid activation in the last step of the decoder.\n",
    "\n",
    "(**Note**: the values inside the data frame `data` and the training code in Part 3 might be helpful.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid activation is used in the last step of the decoder since, firstly, it maps any input value to a range between 0 and 1, ensuring that the reconstructed values follow this contraint. Secondly, it's importatnt to maintain consistency between the input data distribution and the output data distribution, achieving more accurate reconstructions and stabilizing the training process. Lastly, it helps in keeping the gradient values in reasonble range during backpropagation, helping maintain a stable gradient flow which is beneficial for training deep neural networks like autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYwqFWVl1pq8"
   },
   "source": [
    "## Part 3. Training [18] \n",
    "\n",
    "### Part (a) [6 pt]\n",
    "\n",
    "We will train our autoencoder in the following way:\n",
    "\n",
    "- In each iteration, we will hide one of the categorical features using the `zero_out_random_features` function\n",
    "- We will pass the data with one missing feature through the autoencoder, and obtain a reconstruction\n",
    "- We will check how close the reconstruction is compared to the original data -- including the value of the missing feature\n",
    "\n",
    "Complete the code to train the autoencoder, and plot the training and validation loss every few iterations.\n",
    "You may also want to plot training and validation \"accuracy\" every few iterations, as we will define in\n",
    "part (b). You may also want to checkpoint your model every few iterations or epochs.\n",
    "\n",
    "Use `nn.MSELoss()` as your loss function. (Side note: you might recognize that this loss function is not\n",
    "ideal for this problem, but we will use it anyway.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to a PyTorch tensor\n",
    "data_tensor = torch.tensor(datanp)\n",
    "train_set = data_tensor[train_ind]\n",
    "val_set = data_tensor[val_ind]\n",
    "test_set = data_tensor[test_ind]\n",
    "\n",
    "#create dataloader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(TensorDataset(train_set), \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(val_set), \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IDQA_-dS1pq9",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def zero_out_feature(records, feature):\n",
    "    \"\"\" Set the feature missing in records, by setting the appropriate\n",
    "    columns of records to 0\n",
    "    \"\"\"\n",
    "    start_index = cat_index[feature]\n",
    "    stop_index = cat_index[feature] + len(cat_values[feature])\n",
    "    records[:, start_index:stop_index] = 0\n",
    "    return records\n",
    "\n",
    "def zero_out_random_feature(records):\n",
    "    \"\"\" Set one random feature missing in records, by setting the \n",
    "    appropriate columns of records to 0\n",
    "    \"\"\"\n",
    "    return zero_out_feature(records, random.choice(catcols))\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    for col in catcols:\n",
    "        for item in data_loader: # minibatches\n",
    "            data = item[0]\n",
    "            inp = data.detach().numpy()\n",
    "            out = model(zero_out_feature(data.clone(), col)).detach().numpy()\n",
    "            for i in range(out.shape[0]): # record in minibatch\n",
    "                acc += int(get_feature(out[i], col) == get_feature(inp[i], col))\n",
    "                total += 1\n",
    "    return acc / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with accuracy calculation\n",
    "def train(model, train_loader, val_loader, num_epochs=20, learning_rate=1e-4):\n",
    "    torch.manual_seed(42)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data[0]\n",
    "            datam = zero_out_random_feature(data.clone()) # zero out one categorical feature\n",
    "            recon = model(datam)\n",
    "            loss = criterion(recon, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = data[0]\n",
    "                datam = zero_out_random_feature(data.clone())\n",
    "                recon = model(datam)\n",
    "                loss = criterion(recon, data)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        train_accuracy = get_accuracy(model, train_loader)\n",
    "        val_accuracy = get_accuracy(model, val_loader)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "        \n",
    "        # Checkpoint the model\n",
    "        torch.save(model.state_dict(), f'autoencoder_epoch_{epoch+1}.pth')\n",
    "    \n",
    "    # Plotting the losses and accuracies\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs+1), train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(range(1, num_epochs+1), val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WKk01pwx1pq_"
   },
   "source": [
    "### Part (b) [3 pt]\n",
    "\n",
    "While plotting training and validation loss is valuable, loss values are harder to compare\n",
    "than accuracy percentages. It would be nice to have a measure of \"accuracy\" in this problem.\n",
    "\n",
    "Since we will only be imputing missing categorical values, we will define an accuracy measure.\n",
    "For each record and for each categorical feature, we determine whether\n",
    "the model can predict the categorical feature given all the other features of the record.\n",
    "\n",
    "A function `get_accuracy` is written for you. It is up to you to figure out how to\n",
    "use the function. **You don't need to submit anything in this part.**\n",
    "To earn the marks, correctly plot the training and validation accuracy every few \n",
    "iterations as part of your training curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bHWLfCzM1pq_",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader):\n",
    "    \"\"\"Return the \"accuracy\" of the autoencoder model across a data set.\n",
    "    That is, for each record and for each categorical feature, \n",
    "    we determine whether the model can successfully predict the value\n",
    "    of the categorical feature given all the other features of the \n",
    "    record. The returned \"accuracy\" measure is the percentage of times \n",
    "    that our model is successful.\n",
    "        \n",
    "    Args:\n",
    "       - model: the autoencoder model, an instance of nn.Module\n",
    "       - data_loader: an instance of torch.utils.data.DataLoader\n",
    "\n",
    "    Example (to illustrate how get_accuracy is intended to be called.\n",
    "             Depending on your variable naming this code might require\n",
    "             modification.)\n",
    "\n",
    "        >>> model = AutoEncoder()\n",
    "        >>> vdl = torch.utils.data.DataLoader(data_valid, batch_size=256, shuffle=True)\n",
    "        >>> get_accuracy(model, vdl)\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    for col in catcols:\n",
    "        for item in data_loader: # minibatches\n",
    "            data = item[0]\n",
    "            inp = data.detach().numpy()\n",
    "            out = model(zero_out_feature(data.clone(), col)).detach().numpy()\n",
    "            for i in range(out.shape[0]): # record in minibatch\n",
    "                acc += int(get_feature(out[i], col) == get_feature(inp[i], col))\n",
    "                total += 1\n",
    "    return acc / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SxCTlXoV1prB"
   },
   "source": [
    "### Part (c) [4 pt]\n",
    "\n",
    "Run your updated training code, using reasonable initial hyperparameters.\n",
    "\n",
    "Include your training curve in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nj5b71l-1prC",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.2183, Validation Loss: 0.1407, Train Accuracy: 0.3853, Validation Accuracy: 0.3843\n",
      "Epoch 2/20, Train Loss: 0.0811, Validation Loss: 0.0713, Train Accuracy: 0.4598, Validation Accuracy: 0.4586\n",
      "Epoch 3/20, Train Loss: 0.0707, Validation Loss: 0.0702, Train Accuracy: 0.4598, Validation Accuracy: 0.4586\n",
      "Epoch 4/20, Train Loss: 0.0698, Validation Loss: 0.0695, Train Accuracy: 0.4598, Validation Accuracy: 0.4586\n",
      "Epoch 5/20, Train Loss: 0.0690, Validation Loss: 0.0684, Train Accuracy: 0.4598, Validation Accuracy: 0.4586\n",
      "Epoch 6/20, Train Loss: 0.0678, Validation Loss: 0.0669, Train Accuracy: 0.4598, Validation Accuracy: 0.4586\n",
      "Epoch 7/20, Train Loss: 0.0656, Validation Loss: 0.0637, Train Accuracy: 0.4892, Validation Accuracy: 0.4882\n",
      "Epoch 8/20, Train Loss: 0.0612, Validation Loss: 0.0585, Train Accuracy: 0.5222, Validation Accuracy: 0.5219\n",
      "Epoch 9/20, Train Loss: 0.0572, Validation Loss: 0.0558, Train Accuracy: 0.5414, Validation Accuracy: 0.5434\n",
      "Epoch 10/20, Train Loss: 0.0556, Validation Loss: 0.0551, Train Accuracy: 0.5537, Validation Accuracy: 0.5547\n",
      "Epoch 11/20, Train Loss: 0.0548, Validation Loss: 0.0548, Train Accuracy: 0.5635, Validation Accuracy: 0.5651\n",
      "Epoch 12/20, Train Loss: 0.0544, Validation Loss: 0.0542, Train Accuracy: 0.5651, Validation Accuracy: 0.5664\n",
      "Epoch 13/20, Train Loss: 0.0539, Validation Loss: 0.0535, Train Accuracy: 0.5679, Validation Accuracy: 0.5690\n",
      "Epoch 14/20, Train Loss: 0.0534, Validation Loss: 0.0529, Train Accuracy: 0.5700, Validation Accuracy: 0.5703\n",
      "Epoch 15/20, Train Loss: 0.0529, Validation Loss: 0.0527, Train Accuracy: 0.5706, Validation Accuracy: 0.5712\n",
      "Epoch 16/20, Train Loss: 0.0522, Validation Loss: 0.0510, Train Accuracy: 0.5748, Validation Accuracy: 0.5747\n",
      "Epoch 17/20, Train Loss: 0.0502, Validation Loss: 0.0489, Train Accuracy: 0.5722, Validation Accuracy: 0.5748\n",
      "Epoch 18/20, Train Loss: 0.0482, Validation Loss: 0.0473, Train Accuracy: 0.5694, Validation Accuracy: 0.5709\n",
      "Epoch 19/20, Train Loss: 0.0470, Validation Loss: 0.0464, Train Accuracy: 0.5743, Validation Accuracy: 0.5752\n",
      "Epoch 20/20, Train Loss: 0.0466, Validation Loss: 0.0460, Train Accuracy: 0.5770, Validation Accuracy: 0.5780\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoEncoder()\n",
    "train(model, train_loader, val_loader, num_epochs=20, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h9xTwIf51prF"
   },
   "source": [
    "### Part (d) [5 pt]\n",
    "\n",
    "Tune your hyperparameters, training at least 4 different models (4 sets of hyperparameters).\n",
    "\n",
    "Do not include all your training curves. Instead, explain what hyperparameters\n",
    "you tried, what their effect was, and what your thought process was as you \n",
    "chose the next set of hyperparameters to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Define the custom AutoEncoder class with tunable hyperparameters\n",
    "class customAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=57, \n",
    "                 hidden_dims_encoder=[40, 20, 11], \n",
    "                 hidden_dims_decoder=[20, 40, 57]):\n",
    "        super(customAutoEncoder, self).__init__()\n",
    "        # Build the encoder\n",
    "        encoder_layers = []\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_dims_encoder:\n",
    "            encoder_layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            encoder_layers.append(nn.ReLU())\n",
    "            prev_dim = hidden_dim\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "\n",
    "        # Build the decoder\n",
    "        decoder_layers = []\n",
    "        prev_dim = hidden_dims_encoder[-1]\n",
    "        for hidden_dim in hidden_dims_decoder:\n",
    "            decoder_layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            decoder_layers.append(nn.ReLU())\n",
    "            prev_dim = hidden_dim\n",
    "        decoder_layers[-1] = nn.Sigmoid()  # Replace last ReLU with Sigmoid\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different sets of hyperparameters to tune\n",
    "input_dims = [57]  # Keeping it consistent for now\n",
    "hidden_dims_encoder = [[40, 20, 11], \n",
    "                       [60, 30, 11]]  # Increased dims encoder\n",
    "hidden_dims_decoder = [[20, 40, 57], \n",
    "                       [30, 60, 57]]  # Increased dims decoder\n",
    "learning_rates = [1e-4, \n",
    "                  1e-3]  # increased learning rates\n",
    "batch_sizes = [64, \n",
    "               32]  # decreased learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Hyperparameter tuning function\n",
    "def hyperpara_tuned(model, checkpoint_dir, num_epochs=20, learning_rate=1e-4, batch_size=64):\n",
    "    torch.manual_seed(42)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(train_set), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(val_set), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    last_train_loss = float('inf')\n",
    "    last_val_loss = float('inf')\n",
    "    last_train_acc = 0\n",
    "    last_val_acc = 0\n",
    "\n",
    "    #Make sure the checkpoint directory exists\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data[0]\n",
    "            datam = zero_out_random_feature(data.clone())  # zero out one categorical feature\n",
    "            recon = model(datam)\n",
    "            loss = criterion(recon, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = data[0]\n",
    "                datam = zero_out_random_feature(data.clone())\n",
    "                recon = model(datam)\n",
    "                loss = criterion(recon, data)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        train_accuracy = get_accuracy(model, train_loader)\n",
    "        val_accuracy = get_accuracy(model, val_loader)\n",
    "\n",
    "        if train_loss < last_train_loss:\n",
    "            last_train_loss = train_loss\n",
    "\n",
    "        if val_loss < last_val_loss:\n",
    "            last_val_loss = val_loss\n",
    "        \n",
    "        if train_accuracy > last_train_acc:\n",
    "            last_train_acc = train_accuracy\n",
    "\n",
    "        if val_accuracy > last_val_acc:\n",
    "            last_val_acc = val_accuracy\n",
    "\n",
    "        # Save the model checkpoint for each epoch\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'epoch_{epoch+1}.pth')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "    print(f'Train Loss: {last_train_loss:.4f}, Validation Loss: {last_val_loss:.4f}, Train Accuracy: {last_train_acc:.4f}, Validation Accuracy: {last_val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with input_dim=57, enc_dims=[40, 20, 11], dec_dims=[20, 40, 57], lr=0.0001, batch_size=64\n",
      "Train Loss: 0.0499, Validation Loss: 0.0492, Train Accuracy: 0.5837, Validation Accuracy: 0.5826\n",
      "Training with input_dim=57, enc_dims=[40, 20, 11], dec_dims=[20, 40, 57], lr=0.0001, batch_size=32\n",
      "Train Loss: 0.0430, Validation Loss: 0.0428, Train Accuracy: 0.5920, Validation Accuracy: 0.5888\n",
      "Training with input_dim=57, enc_dims=[40, 20, 11], dec_dims=[20, 40, 57], lr=0.001, batch_size=64\n",
      "Train Loss: 0.0275, Validation Loss: 0.0275, Train Accuracy: 0.6218, Validation Accuracy: 0.6162\n",
      "Training with input_dim=57, enc_dims=[40, 20, 11], dec_dims=[20, 40, 57], lr=0.001, batch_size=32\n",
      "Train Loss: 0.0198, Validation Loss: 0.0196, Train Accuracy: 0.6245, Validation Accuracy: 0.6225\n",
      "Training with input_dim=57, enc_dims=[60, 30, 11], dec_dims=[30, 60, 57], lr=0.0001, batch_size=64\n",
      "Train Loss: 0.0410, Validation Loss: 0.0406, Train Accuracy: 0.5923, Validation Accuracy: 0.5936\n",
      "Training with input_dim=57, enc_dims=[60, 30, 11], dec_dims=[30, 60, 57], lr=0.0001, batch_size=32\n",
      "Train Loss: 0.0364, Validation Loss: 0.0365, Train Accuracy: 0.5990, Validation Accuracy: 0.5974\n",
      "Training with input_dim=57, enc_dims=[60, 30, 11], dec_dims=[30, 60, 57], lr=0.001, batch_size=64\n",
      "Train Loss: 0.0184, Validation Loss: 0.0190, Train Accuracy: 0.6302, Validation Accuracy: 0.6250\n",
      "Training with input_dim=57, enc_dims=[60, 30, 11], dec_dims=[30, 60, 57], lr=0.001, batch_size=32\n",
      "Train Loss: 0.0163, Validation Loss: 0.0168, Train Accuracy: 0.6378, Validation Accuracy: 0.6323\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dirs = [f'/Users/harrynguyen/Documents/GitHub/APS360/Labs/4/model1_checkpoint',\n",
    "                  f'/Users/harrynguyen/Documents/GitHub/APS360/Labs/4/model2_checkpoint',\n",
    "                  f'/Users/harrynguyen/Documents/GitHub/APS360/Labs/4/model3_checkpoint',\n",
    "                  f'/Users/harrynguyen/Documents/GitHub/APS360/Labs/4/model4_checkpoint',\n",
    "                  f'/Users/harrynguyen/Documents/GitHub/APS360/Labs/4/model5_checkpoint',\n",
    "                  f'/Users/harrynguyen/Documents/GitHub/APS360/Labs/4/model6_checkpoint',\n",
    "                  f'/Users/harrynguyen/Documents/GitHub/APS360/Labs/4/model7_checkpoint',\n",
    "                  f'/Users/harrynguyen/Documents/GitHub/APS360/Labs/4/model8_checkpoint']\n",
    "\n",
    "# Tuning hyperparameters\n",
    "i = 0\n",
    "for input_dim in input_dims:\n",
    "    for enc_dims, dec_dims in zip(hidden_dims_encoder, hidden_dims_decoder):\n",
    "        for lr in learning_rates:\n",
    "            for batch_size in batch_sizes:\n",
    "                print(f'Training with input_dim={input_dim}, enc_dims={enc_dims}, dec_dims={dec_dims}, lr={lr}, batch_size={batch_size}')\n",
    "                model = customAutoEncoder(input_dim=input_dim, hidden_dims_encoder=enc_dims, hidden_dims_decoder=dec_dims)\n",
    "                hyperpara_tuned(model, checkpoint_dir=checkpoint_dirs[i], num_epochs=20, learning_rate=lr, batch_size=batch_size)\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Please note that I am aware of making 8 models in total since\n",
    "I am genuinely curious of the connection within a change of each\n",
    "parameter that would lead to my decision on the final pick.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model 1: (original)\n",
    "    - input_dim: 57\n",
    "    - enc_dims = [40, 20, 11]\n",
    "    - dec_dims = [20, 40, 57]\n",
    "    - lr = 0.0001\n",
    "    - batch size = 64\n",
    "--> Train accuracy: 58.37%\n",
    "--> Validation accuracy: 58.26%\n",
    "- This baseline model provides a starting point for comparing \n",
    "the effects of other hyperparameters.\n",
    "\n",
    "Model 2: (Decreased batch size with original config dims and lr)\n",
    "    - input_dim: 57\n",
    "    - enc_dims = [40, 20, 11]\n",
    "    - dec_dims = [20, 40, 57]\n",
    "    - lr = 0.0001\n",
    "    - batch size = 32\n",
    "--> Train accuracy: 59.20%\n",
    "--> validation accuracy: 58.88%\n",
    "- Reducing the batch size resulted in more stable updates and \n",
    "slightly  improved the validation and training accuracy. \n",
    "\n",
    "Model 3: (Increased learning rate with original config dims and batch size)\n",
    "    - input_dim: 57\n",
    "    - enc_dims = [40, 20, 11]\n",
    "    - dec_dims = [20, 40, 57]\n",
    "    - lr = 0.001\n",
    "    - batch size = 64\n",
    "--> Train accuracy: 62.18%\n",
    "--> validation accuracy: 61.62%\n",
    "- A higher learning rate led to faster convergence initially \n",
    "but caused the model to overfit quickly. The observed validation \n",
    "and training accuracy slighty improved. \n",
    "\n",
    "Model 4: (Increased lr and decreased batch size with original config dims)\n",
    "    - input_dim: 57\n",
    "    - enc_dims = [40, 20, 11]\n",
    "    - dec_dims = [20, 40, 57]\n",
    "    - lr = 0.001\n",
    "    - batch size = 32\n",
    "--> Train accuracy: 62.45%\n",
    "--> validation accuracy: 62.25%\n",
    "- Both higher learning rate and lower batch size would inherit the\n",
    "advantage of more stable updates and faster convergence, leading\n",
    "to the most accurate train and validation yet.\n",
    "\n",
    "Model 5: (Increased config dims with original lr and batch size)\n",
    "    - input_dim: 57\n",
    "    - enc_dims = [60, 30, 11]\n",
    "    - dec_dims = [30, 60, 57]\n",
    "    - lr = 0.0001\n",
    "    - batch size = 64\n",
    "--> Train accuracy: 59.23%\n",
    "--> validation accuracy: 59.36%\n",
    "- Increasing the number of hidden units in the encoder and decoder layers \n",
    "improved both training and validation accuracy (compared to model 1)\n",
    "This might be due to the model benefiting from higher capacity, allowing it to \n",
    "better learn and reconstruct the features.\n",
    "\n",
    "Model 6: (Decreased batch size with increased config dims, orignial lr)\n",
    "    - input_dim: 57\n",
    "    - enc_dims = [60, 30, 11]\n",
    "    - dec_dims = [30, 60, 57]\n",
    "    - lr = 0.0001\n",
    "    - batch size = 32\n",
    "--> Train accuracy: 59.90%\n",
    "--> validation accuracy: 59.74%\n",
    "- Decreasing batch size at a higher capacity led to more improved accuracies \n",
    "in both train and validation when comparing to the Model 2. \n",
    "\n",
    "Model 7: (Increased lr with increased config dims, original batch size)\n",
    "    - input_dim: 57\n",
    "    - enc_dims = [60, 30, 11]\n",
    "    - dec_dims = [30, 60, 57]\n",
    "    - lr = 0.001\n",
    "    - batch size = 64\n",
    "--> Train accuracy: 63.02%\n",
    "--> validation accuracy: 62.50%\n",
    "- Increasing learning rate at a higher capacity improved both accuracies \n",
    "with the highest jump yet.\n",
    "\n",
    "Model 8: (Increased lr and config dims with decreased batch size)\n",
    "    - input_dim: 57\n",
    "    - enc_dims = [60, 30, 11]\n",
    "    - dec_dims = [30, 60, 57]\n",
    "    - lr = 0.001\n",
    "    - batch size = 32\n",
    "--> Train accuracy: 63.78%\n",
    "--> validation accuracy: 63.23%\n",
    "- Increasing learning rate and decreaing the batch size at a higher capacity\n",
    "led to the highest train and the second highest validation accuracy.\n",
    "--> **CHOOSE THIS MODEL OF HYPERPARAMETERS** \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymCsZH291prI"
   },
   "source": [
    "## Part 4. Testing [12 pt]\n",
    "\n",
    "### Part (a) [2 pt]\n",
    "\n",
    "Compute and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0OkSbup91prJ",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6284\n"
     ]
    }
   ],
   "source": [
    "# Use the best values from the hyperparameter tuning\n",
    "batch_size = 32\n",
    "test_loader = DataLoader(TensorDataset(test_set), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "best_input_dim = 57\n",
    "best_hidden_dims_encoder = [60, 30, 11]  \n",
    "best_hidden_dims_decoder = [30, 60, 57]\n",
    "best_learning_rate = 1e-3  \n",
    "\n",
    "\n",
    "best_model = customAutoEncoder(input_dim=best_input_dim, hidden_dims_encoder=best_hidden_dims_encoder, hidden_dims_decoder=best_hidden_dims_decoder)\n",
    "best_epoch = '/Users/harrynguyen/Documents/GitHub/APS360/Labs/4/model8_checkpoint/epoch_20.pth'\n",
    "best_model.load_state_dict(torch.load(best_epoch))  # Load the saved model\n",
    "best_model.eval()\n",
    "\n",
    "# Compute test accuracy\n",
    "test_accuracy = get_accuracy(best_model, test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEe9yt6L1prM"
   },
   "source": [
    "### Part (b) [4 pt]\n",
    "\n",
    "Based on the test accuracy alone, it is difficult to assess whether our model\n",
    "is actually performing well. We don't know whether a high accuracy is due to\n",
    "the simplicity of the problem, or if a poor accuracy is a result of the inherent\n",
    "difficulty of the problem.\n",
    "\n",
    "It is therefore very important to be able to compare our model to at least one\n",
    "alternative. In particular, we consider a simple **baseline**\n",
    "model that is not very computationally expensive. Our neural network\n",
    "should at least outperform this baseline model. If our network is not much\n",
    "better than the baseline, then it is not doing well.\n",
    "\n",
    "For our data imputation problem, consider the following baseline model:\n",
    "to predict a missing feature, the baseline model will look at the **most common value** of the feature in the training set. \n",
    "\n",
    "For example, if the feature \"marriage\" is missing, then this model's prediction will be the most common value for \"marriage\" in the training set, which happens to be \"Married-civ-spouse\".\n",
    "\n",
    "What would be the test accuracy of this baseline model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'yredu', 'capgain', 'caploss', 'workhr', 'work_ Federal-gov',\n",
      "       'work_ Local-gov', 'work_ Private', 'work_ Self-emp-inc',\n",
      "       'work_ Self-emp-not-inc', 'work_ State-gov', 'work_ Without-pay',\n",
      "       'marriage_ Divorced', 'marriage_ Married-AF-spouse',\n",
      "       'marriage_ Married-civ-spouse', 'marriage_ Married-spouse-absent',\n",
      "       'marriage_ Never-married', 'marriage_ Separated', 'marriage_ Widowed',\n",
      "       'occupation_ Adm-clerical', 'occupation_ Armed-Forces',\n",
      "       'occupation_ Craft-repair', 'occupation_ Exec-managerial',\n",
      "       'occupation_ Farming-fishing', 'occupation_ Handlers-cleaners',\n",
      "       'occupation_ Machine-op-inspct', 'occupation_ Other-service',\n",
      "       'occupation_ Priv-house-serv', 'occupation_ Prof-specialty',\n",
      "       'occupation_ Protective-serv', 'occupation_ Sales',\n",
      "       'occupation_ Tech-support', 'occupation_ Transport-moving', 'edu_ 10th',\n",
      "       'edu_ 11th', 'edu_ 12th', 'edu_ 1st-4th', 'edu_ 5th-6th',\n",
      "       'edu_ 7th-8th', 'edu_ 9th', 'edu_ Assoc-acdm', 'edu_ Assoc-voc',\n",
      "       'edu_ Bachelors', 'edu_ Doctorate', 'edu_ HS-grad', 'edu_ Masters',\n",
      "       'edu_ Preschool', 'edu_ Prof-school', 'edu_ Some-college',\n",
      "       'relationship_ Husband', 'relationship_ Not-in-family',\n",
      "       'relationship_ Other-relative', 'relationship_ Own-child',\n",
      "       'relationship_ Unmarried', 'relationship_ Wife', 'sex_ Female',\n",
      "       'sex_ Male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the prefix for each categorical feature\n",
    "catcol_prefixes = {\n",
    "    \"work\": \"work_\",\n",
    "    \"marriage\": \"marriage_\",\n",
    "    \"occupation\": \"occupation_\",\n",
    "    \"edu\": \"edu_\",\n",
    "    \"relationship\": \"relationship_\",\n",
    "    \"sex\": \"sex_\"\n",
    "}\n",
    "\n",
    "# Calculate the most common value for each categorical feature in the training set\n",
    "most_common_values = {}\n",
    "for feature, prefix in catcol_prefixes.items():\n",
    "    feature_cols = [col for col in data.columns if col.startswith(prefix)]\n",
    "    feature_data = data[feature_cols].iloc[train_ind]\n",
    "    most_common_col = feature_data.sum().idxmax()  # Column with the highest sum\n",
    "    most_common_value = most_common_col.replace(prefix, \"\")\n",
    "    most_common_values[feature] = most_common_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common values for each categorical feature in the training set:\n",
      "{'work': ' Private', 'marriage': ' Married-civ-spouse', 'occupation': ' Prof-specialty', 'edu': ' HS-grad', 'relationship': ' Husband', 'sex': ' Male'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Most common values for each categorical feature in the training set:\")\n",
    "print(most_common_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to compute baseline accuracy\n",
    "def baseline_accuracy2(test_set, most_common_values, catcol_prefixes):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for feature, prefix in catcol_prefixes.items():\n",
    "        feature_cols = [col for col in data.columns if col.startswith(prefix)]\n",
    "        feature_indices = [data.columns.get_loc(col) for col in feature_cols]\n",
    "        feature_data = test_set[:, feature_indices]\n",
    "        most_common_value = most_common_values[feature]\n",
    "        most_common_col = f\"{prefix}{most_common_value}\"\n",
    "        most_common_index = data.columns.get_loc(most_common_col)\n",
    "        # Check if the most common value is the max value (argmax) in the one-hot encoding\n",
    "        correct_predictions += (feature_data.argmax(axis=1) == (feature_indices.index(most_common_index))).sum().item()\n",
    "        total_predictions += feature_data.shape[0]\n",
    "    \n",
    "    return correct_predictions / total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.4569\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoader for test set\n",
    "test_loader = DataLoader(TensorDataset(test_set), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Calculate the test accuracy of this baseline model\n",
    "baseline_test_accuracy = baseline_accuracy2(data_tensor[test_ind], most_common_values, catcol_prefixes)\n",
    "print(f'Baseline Test Accuracy: {baseline_test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QlHu0wxh1prP"
   },
   "source": [
    "### Part (c) [1 pt]\n",
    "\n",
    "How does your test accuracy from part (a) compared to your basline test accuracy in part (b)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy from part (a) is 62.84%, which is significantly higher than the baseline test accuracy of 45.69% in part (b). This indicates that the neural network model is performing better than the baseline model, demonstrating its ability to learn and generalize from the data more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DfQPgu1Q1prS"
   },
   "source": [
    "### Part (d) [1 pt]\n",
    "\n",
    "Look at the first item in your test data. \n",
    "Do you think it is reasonable for a human\n",
    "to be able to guess this person's education level\n",
    "based on their other features? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Feature Values of the First Test Item:\n",
      "{'work': ' Private', 'marriage': ' Divorced', 'occupation': ' Prof-specialty', 'edu': ' Bachelors', 'relationship': ' Not-in-family', 'sex': ' Male', 'age': 0.65753424, 'hours_per_week': 0.39795917}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nBased on the given features, especially the occupation and work class, \\nit is possible for a human to make an educated guess about the person's education level. \\nHowever, without knowing the specific details of the person's educational background, \\nit would still be challenging to make an accurate guess.\\n\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert \n",
    "test_data_df = pd.DataFrame(data_tensor[test_ind].numpy(), columns=data.columns)\n",
    "\n",
    "# Extract \n",
    "first_test_item = test_data_df.iloc[0]\n",
    "\n",
    "# Create a more readable representation \n",
    "def get_original_features(row):\n",
    "    original_features = {}\n",
    "    for feature, prefix in catcol_prefixes.items():\n",
    "        for col in test_data_df.columns:\n",
    "            if col.startswith(prefix) and row[col] == 1:\n",
    "                original_features[feature] = col.replace(prefix, '')\n",
    "                break\n",
    "    return original_features\n",
    "\n",
    "original_first_test_item = get_original_features(first_test_item)\n",
    "original_first_test_item['age'] = first_test_item['age']\n",
    "original_first_test_item['hours_per_week'] = first_test_item['workhr']\n",
    "\n",
    "print(\"Original Feature Values of the First Test Item:\")\n",
    "print(original_first_test_item)\n",
    "\n",
    "# print(\"\\nAnalysis:\")\n",
    "# print(\"Age:\", original_first_test_item['age'])\n",
    "# print(\"Work Class:\", original_first_test_item.get('work', 'Unknown'))\n",
    "# print(\"Marital Status:\", original_first_test_item.get('marriage', 'Unknown'))\n",
    "# print(\"Occupation:\", original_first_test_item.get('occupation', 'Unknown'))\n",
    "# print(\"Relationship:\", original_first_test_item.get('relationship', 'Unknown'))\n",
    "# print(\"Sex:\", original_first_test_item.get('sex', 'Unknown'))\n",
    "# print(\"Hours per Week:\", original_first_test_item['hours_per_week'])\n",
    "# print(\"Native Country:\", original_first_test_item.get('native_country', 'Unknown'))\n",
    "\n",
    "\"\"\"\n",
    "Based on the given features, especially the occupation and work class, \n",
    "it is possible for a human to make an educated guess about the person's \n",
    "education level, assuming level of education is not given. However, \n",
    "without knowing the  specific details of the person's educational \n",
    "background, it would still be challenging to make an accurate guess.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_d5uuAY1prZ"
   },
   "source": [
    "### Part (e) [2 pt]\n",
    "\n",
    "What is your model's prediction of this person's education\n",
    "level, given their other features?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kBY5gKXR1pra",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's predicted education level: Bachelors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe model's predicted education level for the first test item is \\nAssociate degree - academic, which is reasonable but incorrect.\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract\n",
    "first_test_item_tensor = test_set[0].unsqueeze(0)\n",
    "\n",
    "# Zero out the education feature\n",
    "first_test_item_tensor_zerod = zero_out_feature(first_test_item_tensor.clone(), 'edu')\n",
    "\n",
    "# Pass the modified item \n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed = best_model(first_test_item_tensor_zerod)\n",
    "\n",
    "# Get the one-hot encoded output\n",
    "edu_start_index = cat_index['edu']\n",
    "edu_stop_index = edu_start_index + len(cat_values['edu'])\n",
    "predicted_edu_one_hot = reconstructed[:, edu_start_index:edu_stop_index]\n",
    "\n",
    "predicted_edu_index = predicted_edu_one_hot.argmax(dim=1).item()\n",
    "predicted_edu = list(cat_values['edu'])[predicted_edu_index]\n",
    "\n",
    "print(f\"Model's predicted education level: {predicted_edu}\")\n",
    "\n",
    "'''\n",
    "The model's predicted education level for the first test item is \n",
    "Bachelors, which is correct!\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdLNA0ce1prd"
   },
   "source": [
    "### Part (f) [2 pt]\n",
    "\n",
    "What is the baseline model's prediction\n",
    "of this person's education level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TXgoM9qk1prd",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model's predicted education level: HS-grad\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Extract the most common value for the education feature in the training set\n",
    "edu_prefix = 'edu_'\n",
    "edu_cols = [col for col in data.columns if col.startswith(edu_prefix)]\n",
    "edu_counts = data[edu_cols].iloc[train_ind].sum()\n",
    "most_common_edu_col = edu_counts.idxmax()\n",
    "most_common_edu_value = most_common_edu_col.replace(edu_prefix, '').strip()\n",
    "\n",
    "print(f\"Baseline Model's predicted education level: {most_common_edu_value}\")\n",
    "\n",
    "''' \n",
    "This baseline model uses the most common value for the education feature \n",
    "from the training set to predict the education level for any individual \n",
    "in the test set, including the first person in the testing set.\n",
    "HS-grad turned out to be the most common level of education, hence the\n",
    "guess. However, this is not quite accurate as it guesses HS-grad.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HwjDg1uM1pqe",
    "OEJ0Ci3l1pqh",
    "1_5ZZR_J1pqy",
    "WKk01pwx1pq_",
    "SxCTlXoV1prB",
    "h9xTwIf51prF",
    "UEe9yt6L1prM",
    "QlHu0wxh1prP",
    "DfQPgu1Q1prS",
    "p_d5uuAY1prZ",
    "fdLNA0ce1prd"
   ],
   "name": "Lab 4 - Data Imputation",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
